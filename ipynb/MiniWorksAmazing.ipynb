{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04ccc4f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwQNi3gsH3OV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "254f6107"
      },
      "outputs": [],
      "source": [
        "# file_path = os.path.join('D:', 'MINI PROJECT', 'Data', 'train.csv')\n",
        "file_path = '/content/drive/My Drive/toxic-comment/train.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "496ae92f"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2809fc9a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95dec627"
      },
      "outputs": [],
      "source": [
        "x=df['comment_text']\n",
        "y=df[df.columns[2: ]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "771b5aa9"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d7edd6d"
      },
      "outputs": [],
      "source": [
        "Max_features =  200000 #num of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52e1718f"
      },
      "outputs": [],
      "source": [
        "vectorizer=TextVectorization(max_tokens=Max_features,\n",
        "                             output_sequence_length=1800,\n",
        "                             output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ac1fcf2"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5464af56"
      },
      "outputs": [],
      "source": [
        "vectorizer('Hello world, life is great')[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35d3a055"
      },
      "outputs": [],
      "source": [
        "# vectorizer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4569b394"
      },
      "outputs": [],
      "source": [
        "vectorized_text=vectorizer(x.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83becd9b"
      },
      "outputs": [],
      "source": [
        "vectorized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93d2a47b"
      },
      "outputs": [],
      "source": [
        "dataset=tf.data.Dataset.from_tensor_slices((vectorized_text,y))\n",
        "dataset=dataset.cache()\n",
        "dataset=dataset.shuffle(160000)\n",
        "dataset=dataset.batch(16)\n",
        "dataset=dataset.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb16d2f3"
      },
      "outputs": [],
      "source": [
        "batch_x,batch_y=dataset.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eb3b23f"
      },
      "outputs": [],
      "source": [
        "train=dataset.take(int(len(dataset)*.7))\n",
        "val=dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test=dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53740a46"
      },
      "outputs": [],
      "source": [
        "train.as_numpy_iterator().next()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def perform_web_scraping(url):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        body_text = soup.find('body').get_text()\n",
        "        return body_text\n",
        "    else:\n",
        "        return \"Error: Unable to fetch the web page content.\"\n",
        "\n",
        "# Call the function with your desired URL\n",
        "# result = perform_web_scraping('https://example.com')\n",
        "# print(result)\n"
      ],
      "metadata": {
        "id": "Sc8TzxgBVZ8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "model_path = '/content/drive/My Drive/toxic_comment_classification_model10.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "url=input()\n",
        "input_texttt=perform_web_scraping(url)\n",
        "input_text=vectorizer(input_texttt)\n",
        "prediction = model.predict(np.array([input_text]))\n",
        "column_names = df.columns[2:]\n",
        "\n",
        "prediction_df = pd.DataFrame(prediction, columns=column_names)\n",
        "\n",
        "print(prediction_df)\n",
        "print(input_texttt)\n",
        "# print(prediction_df)\n"
      ],
      "metadata": {
        "id": "kNO8OGXv94ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAR9VKhFdLqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}